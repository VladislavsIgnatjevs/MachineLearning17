# MachineLearning17

This is exercise written for a Machine Learning assignment in university
As a starting point, three image descriptors (digit one, digit five, digit eight) are taken from MNIST handwritten digit database.
The exercise shows the differences, implications of PCA (Principal Component Analysis) and LDA (Latent Dirichlet allocation) 
for dimensionality reduction of the data set

It uses k-means clustering (3 clusters) to partiate date for visibility on the scatter plot.

Finally, it uses SVM with a RBF kernel, SVM
with a linear kernel, and a neural network classifier with one hidden layer to classify the
dataset in a 5-fold cross validation setting

Use PCA to reduce the dimensions of each image descriptor to two using the first two
principal components, and cluster those data points in the 2-D space into 3 clusters using
one of the clustering methods that we have learned in lectures (hierarchical clustering, kmeans,
GMM etc), and plot a scatter plot, that shows the cluster labels. Discuss whether
the resulting clusters match well the actual ground truth partition of classes, i.e., are
images from the same digit are clustered into one region?
2) Use LDA instead of PCA for dimensionality reduction and repeat Question 1. Plot the
scatter plot after applying LDA. Compare the results from Question 1, and discuss.
3) Now consider separating the images of digit ‘5’ from the rest (the images of ‘1’ and ‘8’).
Note this is now a two-class classification problem. Use SVM with a RBF kernel, SVM
with a linear kernel, and a neural network classifier with one hidden layer to classify the
dataset in a 5-fold cross validation setting. Compare and discuss the results using the
obtained validation accuracy. Create and plot the ROC curves of the results using the
three different classifiers, and compare their performance using the area under the ROC
curve (AUC). Pick one parameter (e.g., a penalty parameter, or a parameter from a
kernel) from SVM, and show that how you can properly tune a parameter on this dataset. 
